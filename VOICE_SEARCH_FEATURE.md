# Speech-to-Text Feature Documentation

## Overview
The product recommendation system now includes **Voice Search** functionality using OpenAI's Whisper model via Gradio API. Users can speak their search queries instead of typing them.

---

## Features

### ğŸ¤ Voice Input
- **Click microphone button** to start recording
- **Speak your query** (up to 10 seconds)
- **Automatic transcription** using Whisper AI
- **Text appears** in search box
- **Search or refine** the transcribed text

### âš¡ Real-time Feedback
- **Recording indicator**: Red pulsing microphone button
- **Processing indicator**: Yellow spinner
- **Status messages**: "Listening...", "Processing...", "Success!"
- **Error handling**: Clear error messages with auto-dismiss

### ğŸ”’ Privacy & Security
- **No backend storage**: API calls directly from browser
- **Microphone permissions**: Browser-level control
- **Temporary recording**: Audio not saved permanently

---

## How It Works

### User Flow
```
1. User clicks microphone button (ğŸ¤)
   â†“
2. Browser requests microphone permission
   â†“
3. User speaks search query (max 10 seconds)
   â†“
4. Recording stops automatically
   â†“
5. Audio sent to Whisper API via Gradio
   â†“
6. Transcribed text returned
   â†“
7. Text appears in search box
   â†“
8. User can edit or search immediately
```

### Technical Flow
```javascript
// 1. User clicks voice button
handleVoiceInput() called
  â†“
// 2. Request microphone access
navigator.mediaDevices.getUserMedia({ audio: true })
  â†“
// 3. Record audio
MediaRecorder API captures audio
  â†“
// 4. Create audio blob
Blob created with type 'audio/wav'
  â†“
// 5. Send to Whisper API
Client.connect("openai/whisper")
client.predict("/predict", { inputs: audioBlob, task: "transcribe" })
  â†“
// 6. Receive transcription
result.data contains transcribed text
  â†“
// 7. Update search input
setPrompt(transcribedText)
```

---

## API Integration

### Whisper Model Details
- **Model**: `openai/whisper`
- **Endpoint**: `/predict`
- **Task**: `transcribe`
- **Input**: Audio blob (WAV format)
- **Output**: Transcribed text string

### API Call Example
```javascript
import { Client } from "@gradio/client";

const client = await Client.connect("openai/whisper");
const result = await client.predict("/predict", {
  inputs: audioBlob,  // Audio file blob
  task: "transcribe"  // Transcription task
});

const transcribedText = result.data; // "laptop with good battery life"
```

### Error Handling
```javascript
try {
  const text = await speechToText(10);
  setPrompt(text);
} catch (error) {
  if (error.message.includes("denied")) {
    // Microphone permission denied
  } else if (error.message.includes("not supported")) {
    // Browser doesn't support audio recording
  } else {
    // API or network error
  }
}
```

---

## Code Implementation

### 1. Speech-to-Text Service (`speechToTextService.js`)

#### `transcribeAudio(audioBlob)`
Sends audio to Whisper API for transcription.

```javascript
export const transcribeAudio = async (audioBlob) => {
  const client = await Client.connect("openai/whisper");
  const result = await client.predict("/predict", {
    inputs: audioBlob,
    task: "transcribe"
  });
  return result.data.trim();
};
```

#### `recordAudio(maxDuration)`
Records audio from user's microphone.

```javascript
export const recordAudio = (maxDuration = 10) => {
  return new Promise((resolve, reject) => {
    navigator.mediaDevices.getUserMedia({ audio: true })
      .then(stream => {
        const mediaRecorder = new MediaRecorder(stream);
        const audioChunks = [];
        
        mediaRecorder.ondataavailable = (event) => {
          audioChunks.push(event.data);
        };
        
        mediaRecorder.onstop = () => {
          const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
          resolve(audioBlob);
        };
        
        mediaRecorder.start();
        
        // Auto-stop after maxDuration
        setTimeout(() => {
          if (mediaRecorder.state === 'recording') {
            mediaRecorder.stop();
          }
        }, maxDuration * 1000);
      })
      .catch(reject);
  });
};
```

#### `speechToText(maxDuration)`
Complete workflow: record + transcribe.

```javascript
export const speechToText = async (maxDuration = 10) => {
  const audioBlob = await recordAudio(maxDuration);
  const transcribedText = await transcribeAudio(audioBlob);
  return transcribedText;
};
```

### 2. Main App Integration (`ProductRecommendationApp.jsx`)

#### State Management
```javascript
const [isRecording, setIsRecording] = useState(false);
const [isSpeechProcessing, setIsSpeechProcessing] = useState(false);
const [speechError, setSpeechError] = useState(null);
```

#### Voice Input Handler
```javascript
const handleVoiceInput = async () => {
  try {
    setSpeechError(null);
    setIsRecording(true);
    
    const transcribedText = await speechToText(10);
    
    setIsRecording(false);
    setIsSpeechProcessing(true);
    
    setPrompt(transcribedText);
    setIsSpeechProcessing(false);
    
  } catch (error) {
    setIsRecording(false);
    setIsSpeechProcessing(false);
    setSpeechError(error.message);
    setTimeout(() => setSpeechError(null), 5000);
  }
};
```

#### UI Components
```jsx
{/* Microphone Button */}
<button
  onClick={handleVoiceInput}
  disabled={isLoading || isRecording || isSpeechProcessing}
  className="voice-btn"
  style={{
    background: isRecording ? '#ef4444' : '#8b5cf6',
    animation: isRecording ? 'pulse 1.5s infinite' : 'none'
  }}
>
  {isRecording ? <MicOff /> : <Mic />}
</button>

{/* Status Messages */}
{isRecording && <span>ğŸ¤ Listening... Speak now!</span>}
{isSpeechProcessing && <span>â³ Processing your speech...</span>}
{speechError && <span>âŒ {speechError}</span>}
```

---

## UI/UX Design

### Visual States

#### 1. **Idle State** (Ready to record)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ” [Search input...] ğŸ¤ [Search] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
Purple microphone button
```

#### 2. **Recording State** (Listening)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ” [Search input...] ğŸ”´ [Search] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
ğŸ¤ Listening... Speak now!

Red pulsing microphone button
```

#### 3. **Processing State** (Transcribing)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ” [Search input...] â³ [Search] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â³ Processing your speech...

Yellow spinner
```

#### 4. **Success State** (Text added)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ” laptop with battery life ğŸ¤ [Search] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Transcribed text in input, ready to search
```

#### 5. **Error State**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ” [Search input...] ğŸ¤ [Search] â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
âŒ Microphone access denied

Error message (auto-dismisses in 5 seconds)
```

### Color Coding
- **Purple (#8b5cf6)**: Idle/Ready state
- **Red (#ef4444)**: Recording state (with pulse animation)
- **Yellow (#facc15)**: Processing state
- **Red (#ef4444)**: Error state

---

## Usage Examples

### Example 1: Basic Voice Search
```
1. User clicks ğŸ¤ microphone button
2. User says: "laptop with good battery life"
3. System transcribes: "laptop with good battery life"
4. Text appears in search box
5. User clicks "Find Products"
6. System detects aspects: ["battery life"]
7. ABSA analysis runs automatically
```

### Example 2: Voice Search with Aspects
```
1. User clicks ğŸ¤
2. User says: "I need a laptop with excellent display and performance"
3. Transcribed: "I need a laptop with excellent display and performance"
4. User clicks search
5. Aspects detected: ["display", "performance"]
6. Products ranked by sentiment
```

### Example 3: Voice + Manual Refinement
```
1. User clicks ğŸ¤
2. User says: "gaming laptop"
3. Transcribed: "gaming laptop"
4. User edits to add: "gaming laptop with cooling"
5. User searches
6. Aspect detected: ["cooling"]
7. Analysis runs
```

### Example 4: Error Recovery
```
1. User clicks ğŸ¤
2. Microphone access denied
3. Error shown: "Microphone access denied..."
4. User grants permission in browser
5. User clicks ğŸ¤ again
6. Recording works
```

---

## Browser Compatibility

### Supported Browsers
- âœ… **Chrome/Edge** 90+ (Full support)
- âœ… **Firefox** 88+ (Full support)
- âœ… **Safari** 14.1+ (Full support)
- âœ… **Opera** 76+ (Full support)

### Required APIs
- `navigator.mediaDevices.getUserMedia()` - Microphone access
- `MediaRecorder` - Audio recording
- `Blob` - Audio data handling
- `fetch` - API calls

### Fallback Behavior
If browser doesn't support voice input:
- Microphone button hidden or disabled
- User can still type manually
- Error message: "Your browser does not support audio recording"

---

## Testing

### Test Case 1: Basic Recording
```
1. Click microphone button
2. Allow microphone permission
3. Say: "laptop"
4. Wait for transcription
5. Verify: "laptop" appears in search box
```

### Test Case 2: Long Query
```
1. Click microphone
2. Say: "I'm looking for a laptop with good battery life, excellent display, and strong performance"
3. Verify: Full sentence transcribed
4. Verify: Aspects detected (battery life, display, performance)
```

### Test Case 3: Multiple Languages (if supported)
```
1. Click microphone
2. Say query in different language
3. Verify: Transcription in that language
```

### Test Case 4: Noise Handling
```
1. Test in quiet environment â†’ Clear transcription
2. Test with background noise â†’ May have errors
3. Verify: User can edit transcribed text
```

### Test Case 5: Error Handling
```
1. Deny microphone permission â†’ Error message shown
2. Block API access â†’ Error message shown
3. Verify: Errors auto-dismiss after 5 seconds
```

---

## Performance Considerations

### Recording
- **Audio format**: WAV (browser default)
- **Duration**: Max 10 seconds (configurable)
- **File size**: ~100-500 KB per recording

### API Call
- **Average latency**: 2-5 seconds
- **Success rate**: ~44% (from API stats)
- **Timeout**: None (waits for response)

### Optimization Tips
1. **Keep recordings short** (< 10 seconds)
2. **Record in quiet environment**
3. **Speak clearly** and at normal pace
4. **Use headset** for better quality

---

## Troubleshooting

### Issue: "Microphone access denied"
**Solution:**
1. Check browser permissions (address bar icon)
2. Allow microphone access
3. Reload page if needed

### Issue: "No transcription returned"
**Solution:**
1. Ensure you spoke during recording
2. Check if microphone is working (test in other apps)
3. Try recording again

### Issue: Incorrect transcription
**Solution:**
1. Speak more clearly
2. Reduce background noise
3. Manually edit the transcribed text
4. Try typing instead

### Issue: "Browser does not support audio recording"
**Solution:**
1. Update browser to latest version
2. Use supported browser (Chrome, Firefox, Safari, Edge)
3. Use manual typing as alternative

---

## Future Enhancements

### 1. **Multi-language Support**
- Detect language automatically
- Support non-English queries
- Language selector

### 2. **Voice Commands**
- "Search for..." â†’ triggers search
- "Filter by..." â†’ opens filter modal
- "Reset" â†’ clears search

### 3. **Continuous Recording**
- Manual stop button
- No 10-second limit
- Real-time transcription preview

### 4. **Voice Feedback**
- Text-to-speech for results
- Voice confirmation
- Audio notifications

### 5. **Advanced Features**
- Speaker identification
- Accent detection
- Noise cancellation

---

## Security & Privacy

### Data Handling
- âœ… Audio recorded temporarily in browser memory
- âœ… Sent directly to Whisper API (no backend)
- âœ… Not stored on servers
- âœ… Not logged or analyzed

### Permissions
- âœ… Microphone access requested per-session
- âœ… User can revoke anytime
- âœ… Clear permission prompts
- âœ… Works without microphone (fallback to typing)

### API Security
- âœ… Uses official Gradio client
- âœ… HTTPS connections
- âœ… No authentication required (public model)
- âœ… No user data collected

---

## Summary

âœ… **Voice search** integrated with Whisper AI
âœ… **Real-time transcription** (2-5 seconds)
âœ… **Visual feedback** (recording, processing, error states)
âœ… **Error handling** with user-friendly messages
âœ… **Browser compatibility** (Chrome, Firefox, Safari, Edge)
âœ… **No backend required** (direct API calls)
âœ… **Privacy-focused** (no audio storage)
âœ… **Seamless integration** with existing search
âœ… **Works with ABSA** (aspect detection from voice)
âœ… **Fully documented** with examples

Users can now **speak their searches** making the product discovery experience more natural and accessible! ğŸ¤
